\documentclass{article}



\usepackage[portrait, headheight = 0cm, margin=0.25cm, top = 0.25cm]{geometry} 
\usepackage[export]{adjustbox} 
\usepackage{graphicx}
\usepackage[dvipsnames,table]{xcolor} % [dvipsnames,table] for setting colors \usepackage{amsmath} \usepackage{xfrac}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{shapes.misc}
%\usetikzlibrary{external}
%\tikzexternalize % activate!
%\usepackage{sparklines}
\usepackage{xfrac}
\usepackage[space]{grffile}
\usepackage{hyperref}

\DeclareRobustCommand\Tstrut{\rule{0pt}{2.6ex}}         % = `top' strut
\DeclareRobustCommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   % = `bottom' strut
\renewcommand{\familydefault}{\sfdefault}

\begin{document}
<<,cache=FALSE, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results="hide">>=
# this chunk is common to all child documents
require(stringi)
require(scales)
require(digest)
require(clue)
require(FRAPO)
require(data.table)
require(Matrix)
require(Matrix.utils)
require(magrittr)
require(gsubfn)
require(Hmisc)
require(ggplot2)
require(magick)
require(DBI)
require(readxl)
require(Rtsne)
require(knitr)

@


\tableofcontents

<<,cache=FALSE, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results="hide">>=

x<-list.files(path="figure",full.names = TRUE)
if(length(x)>0)file.remove(x)

source("https://raw.githubusercontent.com/satrapade/latex_utils/master/latex_helpers_v2.R")


qcr_ccys<-c(
  "USD",
  "EUR",
  "JPY",
  "GBP",
  "AUD",
  "CAD",
  "CHF",
  "SEK",
  "NZD",
  "NOK"
)


@

\newpage
\section{``Review of Technical Signals'' document}

\subsection{The signals}

\vskip 5mm

The document begins by introducing the singals used by the proposed strategy. As per the document, these signals considered 
to be ``robust representations of factor risk premia``. The specific mapping is not clearly and explicitly presented
in the introduction, but it is fairly straight-forward \footnote{Ang, Andrew. A systematic Approach to Factor Investing.  
Oxford University Press 2014}. The document states that 

We were not able to decide which premium is captured by the ``yield momentum'' signal. 


\vskip 5mm

\begin{center}
\begin{tabular}{l l l}
\hline
\multicolumn{3}{c}{QCR signals} \\
\hline
signal & type & risk premium \\
price momentum & technical & momentum \\
price reversion & technical & volatility \\
yield momentum &  fundamental & {\bf no risk premium presented} \\
risk-adjusted yield & fundamental & value/carry\\
long-term fair value & fundamental & value/carry \\
short-term fair value & fundamental & value/carry \\
\end{tabular}
\end{center}


\vskip 5mm

\begin{center}
\begin{tabular}{c}
\hline
\rowcolor{gray!20}
Risk factors associated to risk premia and asset classes in {\bf ANG}, 2014 \\
\Sexpr{web_png(
  "https://user-images.githubusercontent.com/1358190/42994323-b1dd6fe4-8c05-11e8-92e6-1c64972ed88c.png",
  height="10cm",
  width="15cm"
)}
\end{tabular}
\end{center}



\noindent Some of these risk factors do not behave as one would expect them to behave, these are usually called  , ``time-series momentum'' is considered to be a ``market anomaly'', 
not a ``risk-premium'' \footnote{For example see the introduction in Tobias J. Moskowitz, Yao Hua Ooi, Lasse Heje Pedersen. 
Time series momentum. Journal of Financial Economics 104(2012) 228-250}.

\vskip 5mm

Anomalies, in addition to momentum, include the various calendar effects in equities  and fairly large list of other 
``price patterns'', not all of which are exploitable. Price momentum is the most important entry in the list of
anomalies. The two concepts are not orthogonal, but they are sufficiently different in the minds of most informed investors
that one should make an effort to align terminology to general useage. 

\vskip 5mm

\noindent It might be helpful to exactly spell out what the specific risk-premia are that we aim to capture. 

\vskip 5mm

\href{https://s3.amazonaws.com/papers-documentation/Books+-+Market+Factors/(Financial+Management+Association+Survey+and+Synthesis+Series)+Andrew+Ang-Asset+Management_+A+Systematic+Approach+to+Factor+Investing-Oxford+University+Press+(2014)+(1).pdf}{\bf 
Ang, Andrew. A systematic Approach to Factor Investing. Oxford University Press 2014}

\noindent Furthermore, the signals are 

\newpage
\subsection{``Diminishing returns to diversification''}
<<,cache=FALSE, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results="hide">>=
tri<-function(n,d=1,s=1)(s*row(diag(n))<s*col(diag(n)))+d*diag(n)

tret_rv<- 50 %>% # random returns, random vol for testing
  {mapply(rnorm,sd=runif(.),MoreArgs=list(n=1000),SIMPLIFY=FALSE)} %>%
  {do.call(cbind,.)} 

tret<- 50 %>%  # random returns, equal vol
  {rnorm(10000*.,mean=1,sd=1)} %>% 
  {matrix(.,ncol=length(.)/10000)}

ptfs<- tri(ncol(tret))%*%diag(1/seq(ncol(tret)))

vars<-setNames(apply(tret%*%ptfs,2,var),seq(ncol(tret)))
vols<-setNames(apply(tret%*%ptfs,2,sd),seq(ncol(tret)))
sharpes<-setNames(apply(tret%*%ptfs,2,function(x)mean(x)/sd(x)),seq(ncol(tret)))

diversification<-data.table(
  assets=seq(ncol(tret)),
  var=vars,
  vol=vols
) %>% 
  melt(id.vars="assets",measure.vars=c("var","vol"))


quality<-data.table(
  assets=seq(ncol(tret)),
  sharpe=sharpes
) %>% 
  melt(id.vars="assets",measure.vars=c("sharpe"))


gg1 <- diversification %>% 
  ggplot() + 
  geom_vline(color=rgb(0.2,0.2,0.2),xintercept=4) +
  geom_vline(color=rgb(0.2,0.2,0.2),xintercept=30) +
  geom_line(aes(x=assets,y=value,col=variable),size=2) 

gg2 <- quality %>% 
  ggplot() + 
  geom_vline(color=rgb(0.2,0.2,0.2),xintercept=4) +
  geom_vline(color=rgb(0.2,0.2,0.2),xintercept=30) +
  geom_line(aes(x=assets,y=value,col=variable),size=2) 

 
@

The document

Page 4 of the ``Review of Technical Signals'' document examines the marginal reduction of portfolio variance as a function
of the number of uncorrelated assets in the portfolio. The claim is that ``there is little diversification benefit for
each currency we include beyond the major three or four''. A plot of portfolio variance and volatility as a function of 
the number of i.i.d $\mu(1,1)$ variables added to the portfolio illustrates the argument:

\begin{center}
\Sexpr{make_plot(
  plot(gg1),
  width="15cm",
  height="15cm",
  envir=environment()
)}
\end{center}

However:

\begin{itemize}
\item The ``\% of total variance explained`` is relevant for choosing the degrees of freedom we want our model to have.
\item In the context of portfolio construction (which the notion of ``diversification'' applies to), \% of total variance 
is not the relevant statistic. 
\item What we care about is the portfolio sharpe ratio.
\item Because: the metrics investors focus on (expected maximum drawdown, expected length of drawdown) scale with the sharpe ratio.
\item The sharpe ratio scales inversely to portfolio volatility.
\item We should examine how the sharpe ratio changes as we add assets to our portfolio.
\item For uncorrelated assets with positive expected returns there is a clear benefit to ``returns quality'' well 
beyond 4 assets.
\end{itemize}

\newpage 


Specifically:

\begin{itemize}
\item If we plot the portfolio sharpe ratio vs number of assets, it is clear that the ``30-asset'' porfolio 
has a sharpe ratio that is about \Sexpr{round(sharpes[30]/sharpes[4],digits=2)} times larger
than the sharpe ratio of the ``4-asset'' portfolio. 
\item This difference is definitely not immaterial. 
\item The larger portfolio is much more appealing from the investor's perspective. 
\item It is reasonable to expect that the larger basket would result in a more marketable product.
\end{itemize}

\begin{center}
\Sexpr{make_plot(
  plot(gg2),
  width="15cm",
  height="15cm",
  envir=environment()
)}
\end{center}

Moreover:

\begin{itemize}
\item Real-world assets have time-varying correlations. 
\item The ``effective number of uncorrelated assets'' is smaller than the actual number of assets in the portfolio. 
\item To protect against this effect, it is prudent to add as many assets as we can possibly identify since our 
diversification estimates are quite likely to be optimistic during periods of market stress.
\end{itemize}

\vskip 5mm

In conclusion:

\begin{itemize}
\item we recommend that the number of assets in any systematic strategy be limited by operational
concerns and not by the expected marginal reduction of portfolio variance.
\item currency liquidity should be viewed in relation to strategy AUM, not in relation to total
FX market flows. There is no reason to exclude TRY, RUB, ZAR, BRL, DKK, PLN, TWD if market liquidity
can accomodate expected position sizes. 
\end{itemize}


\newpage
\section{Page 5, Splitting the opportunity set}

An argument is made in favor of splitting the opportunity set (G10) into a ``trend'' subset (G3) and its
complement (G10-ex-G3) used for ``reversion''. The argument rests on the following points:

\vskip 5mm

\begin{description}
\item[Persistence] G3 has the largest marginal share of global FX volumes where trends are most likely. (Bigger ships are slower 
to turn around)
\item[Information content] G3 is most liquid and where most natural order flow is and so there is less transitory volatility 
(noise)  as prices move before bringing in buyers/sellers
\item[Liquidity] It is the most liquid representation of the exchange rate drivers across major economic blocs: North America, 
Europe and Japan
\item[Nature of flows] Exchange rates of these G3 economic blocs are dominated by capital flows rather the external trade 
making them more likely to experience large cumulative deviations from exchange rate equilibrium
\end{description}

\vskip 5mm

\begin{itemize}
\item the reasons for splitting the investment universe into 2 groups are qualitative and vaque
\item there is a significant body of academic research relating to these issues, it would be helpful if
some references were given to present some substantial ecomomic motivation
\end{itemize}


\newpage
\section{Page 6, Simulation results}

\vskip 5mm

We have 3 currency subsets (SUB1, SUB2, SUB3) and 3 signals (SIG1, SIG2, SIG3): 

\vskip 5mm

\begin{center}
\begin{tabular}{l l}
\hline
SIG1 & Price Momentum \\
SIG2 & Price Reversion \\
SIG3 & Yield Momentum \\
SUB1 & G3 \\
SUB2 & G10 \\
SUB3 & G10-ex-G3 \\
\hline
\end{tabular}
\end{center}

\vskip 5mm

\begin{itemize}
\item There are 9 combinations of individual signals with currency subsets that can produce ``Signal results''.
\item We can then combine the resulting P\&L time-series to produce 511(=$2^9$-1) possible ``Portfolio results''.
\item The number of possible combinations may be less depending on how the signals work. If the signals are
use cross sectional ranks (which is usually referred to as ``Momentum'') then we have 511 resuls. If the signals
are ``time-series trend'', i.e. longitudinal then the number of possible results is smaller. We dont have this information.
\item Of the 511 possible combinations, 8 results are presented.
\item It is important to understand the size of this ``implied search space'' to ascertain the possibility
of overfitting
\end{itemize}

\vskip 5mm

\begin{center}
\begin{tabular}{l l l l}
\hline
\rowcolor{gray!20}
\multicolumn{4}{c}{Results presented} \\
\multicolumn{1}{l}{(Subset,Signal) combinations used} & 
\multicolumn{1}{l}{Annualized Return} &
\multicolumn{1}{l}{Sharpe} &
\multicolumn{1}{l}{Volatility} \\
(G10,Price Momentum) & 7 bps & 0 & 150 bps \\
(G3,Price Momentum) & 67 bps & 0.43 & 150 bps \\
(G10-ex-G3,Price Reversion)  & 196 bps & 0.66 & 296 bps \\
(G10,Price Reversion)  & 179 bps & 0.61 & 296 bps \\
(G3,Price Momentum)+(G10,Yield Momentum) & 330 bps & 0.67 & 500 bps \\
(G10,Price Momentum)+(G10,Yield Momentum) & 186 bps & 0.37 & 500 bps \\
(G10,Price Momentum)+(G10,Yield Momentum)+(G10,Price Reversion) & 488 bps & 0.93 & 528 bps\\
(G3,Price Momentum)+(G10,Yield Momentum)+(G10,Price Reversion) & 636 bps & 1.18 & 538 bps \\
\end{tabular}
\end{center}

\begin{itemize}
\item Results should be normalized to a equal capital deployed for easy comparisons.
\item With the exception of turnover statistics, only the resulting P\&L time-series are characterized.
\item There is a significant improvement in sharpe ratio as individual time-series are combined, 
presumably due to low correlation between portfolio constituents
\item The mechanism for controlling turnover is not explained well.
\item Price momentum P\&L on G3 looks very similar to what one would expect from a typical trend following
strategy applied to this universe.
\item Price momentum P\&L on G10 does not look similar to one would expect from a typical trend following
strategy applied to this universe. Because G10 includes less liquid and more carry-driven currencies it
is important to implement the trend signal properly. FX trend is known to work best for total-return
time-series. Is does the input into the signal calculation take carry income into account?
\end{itemize}


\newpage
\section{Page 13, Peer Review and Validation of Results }

The decision to split the investment universe into a ``G3'' group for trend and 
a ``G10-ex-G3'' group for mean reversion has a major impact on the performance of 
the ``Price Return Momentum'' signal:

\vskip 5mm

\begin{center}
\begin{tabular}{m{7cm} m{7cm}}
\hline
\rowcolor{gray!20}
\multicolumn{2}{c}{Figure 4, page 6 of ``REVIEW OF TECHNICAL SIGNALS'' document} \\
\Sexpr{web_png(
  "https://user-images.githubusercontent.com/1358190/42832568-7fcd6a36-89e9-11e8-9f5c-dc7a3de86afd.PNG",
  height="5cm",
  width="7cm"
)}
&
\Sexpr{web_png(
"https://user-images.githubusercontent.com/1358190/42833184-5b9bc1f6-89eb-11e8-94e7-9ff47cddf0a9.png",
  height="5cm",
  width="7cm"
)}
\\
\end{tabular}
\end{center}

\vskip 5mm

\begin{itemize}

\item it seems that the ``Price Momentum'' signal produces negative annualized returns of about -60bps for the 
``G10-ex-G3'' group of currencies. 

\item It is therefore important to justify the reasons for limiting the proposed price momentum signal to the 
``G3'' subset.

\end{itemize}


On page 13, a reference is made to a ``Major/Minor Split Validation'' document, which seems to contain this
analysis. We did not receive a copy of this document.


\newpage
\section{Benchmarking }

Comparing the strategy with competitor results is useful.


It should be quite easy to produce very simple, base-case systematic benchmarks with 
identical portfolio construction methodology but simplistic signals (for example quarterly
total returns for trend). These would be quite informative.

\newpage
\section{Signals: Trend, Reversion}
<<,cache=FALSE, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results="hide">>=
#
# simple backtest 
#

require(data.table)
require(stringi)
require(magrittr)
require(RcppRoll)

# restricted universe
g10<-c("USD","EUR","JPY","GBP","AUD","CAD","CHF","SEK","NZD", "NOK")

# ccy total returns matrix
ccy_tr <- fread("ccy_tr.csv") %>% # ccy returns
  {as.matrix(.[,-1],rownames=.$rn)} %>%
  {.[,-which(apply(.,2,sd)<1e-10)]} %>%
  {apply(log(.),2,diff)} %>%
  {structure(.%*%diag((0.05/16)/apply(.,2,sd)),dimnames=dimnames(.))} %>%
  {cbind(.,USD=rep(0,nrow(.)))}
 
universe2pairs<-function(u,all_ccy=colnames(get("ccy_tr",parent.frame()))){
  uo<-all_ccy[sort(match(u,all_ccy))]
  m<-outer(uo,uo,paste0)
  m[upper.tri(m)]
}

# make cross returns from subsets
universe2matrix<- function(u,tret){ 
  p<-universe2pairs(u,all_ccy=colnames(tret))
  structure(tret[,stri_sub(p,1,3)]-ccy_tr[,stri_sub(p,-3,-1)],dimnames=list(rownames(tret),p))
}

# make matrix of signals: sign of rolling total returns
tret2sig <- function(x,w=91){
  tret<-structure(apply(x,2,function(p)c(rep(0,w-1),roll_sum(p,n=w))),dimnames=dimnames(x))
  sign(tret)
}

sharpe<-function(strat)sqrt(356)*mean(strat)/sd(strat)

backtest<-function(n,u,dir=1,w=91,tret=get("ccy_tr",parent.frame())){ # name, universe, direction, window
  u_tr<-universe2matrix(u,tret=tret)
  u_sig<-tret2sig(u_tr,w=w)*dir
  u_perf<-head(u_sig,-1)*tail(u_tr,-1)
  strat<-rowMeans(u_perf)
  data.table(
    name=n,
    type=ifelse(dir>0,"trend","reversion"),
    window=w,
    universe=list(u),
    pairs=list(colnames(u_tr)),
    pair_perf=list(u_perf),
    pair_sharpe=list(apply(u_perf,2,function(x)sqrt(356)*mean(x)/sd(x))),
    strat=list(strat),
    sharpe=sharpe(strat),
    vol=100*16*sd(strat),digits=2,
    perf=100*356*mean(strat)
  )
}

backtest_subset<-function(n,u,dir,w,tret,source_backtest){
  force(tret)
  force(w)
  u_pairs<-universe2pairs(u)
  u_perf<-source_backtest$pair_perf[[1]][,u_pairs]*dir
  strat<-rowMeans(u_perf)
  data.table(
    name=n,
    type=ifelse(dir>0,"trend","reversion"),
    window=source_backtest$w[[1]],
    universe=list(u),
    pairs=list(u_pairs),
    pair_perf=list(u_perf),
    pair_sharpe=list(source_backtest$pair_sharpe[[1]][u_pairs]),
    strat=list(strat),
    sharpe=sharpe(strat),
    vol=100*16*sd(strat),digits=2,
    perf=100*356*mean(strat)
  )
}

backtest_subset_ls<-function(n,u,dir,w,tret,source_backtest,s=3){
  force(tret)
  force(w)
  u_pairs_long<-universe2pairs(head(u,s))
  u_pairs_short<-universe2pairs(tail(u,-s))
  u_perf_long<-source_backtest$pair_perf[[1]][,u_pairs_long]
  u_perf_short<-(-1)*source_backtest$pair_perf[[1]][,u_pairs_short]
  strat<-rowMeans(u_perf_long)+rowMeans(u_perf_short)
  data.table(
    name=n,
    type=ifelse(dir>0,"trend","reversion"),
    window=source_backtest$w[[1]],
    universe=list(u),
    pairs=list(c(u_pairs_long,u_pairs_short)),
    pair_perf=list(cbind(u_perf_long,(-1)*u_perf_short)),
    pair_sharpe=list(c(
      source_backtest$pair_sharpe[[1]][u_pairs_long],
      (-1)*source_backtest$pair_sharpe[[1]][u_pairs_short]
    )),
    strat=list(strat),
    sharpe=sqrt(356)*mean(strat)/sd(strat),
    vol=100*16*sd(strat),digits=2,
    perf=100*356*mean(strat)
  )
}



results2df<-function(x)data.table( # formatted results summary
    name=structure(
      x$name,
      hdr=tbl(c("Subset","name"),align="@{}l")
    ),
    strat=structure(
      x$type,
      hdr=tbl(c("Strategy","type"),align="@{}l")
    ),
    window=structure(
      x$window,
      hdr=tbl(c("Window","size"),align="@{}l")
    ),
    pairs=structure(
      mapply(length,x$pairs),
      hdr=tbl(c("Pair","count"),align="@{}l")
    ),
    vol=structure(
      x$vol,
      hdr=tbl(c("Strat","vol"),align="@{}l"),
      format=quote(n_fmt(round(this,digits=2)))
    ),
    perf=structure(
      x$perf,
      hdr=tbl(c("Strat","perf"),align="@{}l"),
      format=quote(n_fmt(round(this,digits=2)))
    ),
    sharpe=structure(
      x$sharpe,
      hdr=tbl(c("Strat","sharpe"),align="@{}l"),
      format=quote(n_fmt(round(this,digits=2)))
    ),
    min_sharpe=structure(
      mapply(min,x$pair_sharpe),
      hdr=tbl(c("Min","pair","sharpe"),align="@{}l"),
      format=quote(n_fmt(round(this,digits=2)))
    ),
    max_sharpe=structure(
      mapply(max,x$pair_sharpe),
      hdr=tbl(c("Max","pair","sharpe"),align="@{}l"),
      format=quote(n_fmt(round(this,digits=2)))
    ),
    mean_sharpe=structure(
      mapply(mean,x$pair_sharpe),
      hdr=tbl(c("Mean","pair","sharpe"),align="@{}l"),
      format=quote(n_fmt(round(this,digits=2)))
    )
  )

results2plot<-function(x)data.table( # results performance plot
  group=rep(x$name,times=mapply(length,x$strat)),
  perf=do.call(c,mapply(cumsum,x$strat,SIMPLIFY=FALSE)),
  date=as.Date(do.call(c,mapply(rownames,x$pair_perf,SIMPLIFY=FALSE)),format="%Y-%m-%d")
)


subsets<-list(g10=g10,g3=head(g10,3),g10xg3=tail(g10,-3),U=colnames(ccy_tr),W=setdiff(colnames(ccy_tr),g10))
random_3subsets<-mapply(function(i)sample(colnames(ccy_tr),3),paste0("sample",1:700),SIMPLIFY=FALSE)
random_7subsets<-mapply(function(i)sample(colnames(ccy_tr),7),paste0("sample",1:700),SIMPLIFY=FALSE)
random_10subsets<-mapply(function(i)sample(colnames(ccy_tr),10),paste0("sample",1:700),SIMPLIFY=FALSE)

batch<-data.table(expand.grid(
    n=names(subsets),
    dir=c(-1,1),
    w=c(91),
    stringsAsFactors = FALSE
)) %>% {.$u<-subsets[.$n];.}

batch_trend_window<-data.table(expand.grid(
    n=c("g3","g10xg3"),
    dir=c(1),
    w=as.integer(seq(from=10,to=360,length.out=50)),
    stringsAsFactors = FALSE
)) %>% {.$u<-subsets[.$n];.}

batch_trend_3subsets<-data.table(expand.grid(
    n=names(random_3subsets),
    dir=c(1),
    w=91,
    stringsAsFactors = FALSE
)) %>% {.$u<-random_3subsets[.$n];.}

batch_trend_7subsets<-data.table(expand.grid(
    n=names(random_7subsets),
    dir=c(1),
    w=91,
    stringsAsFactors = FALSE
)) %>% {.$u<-random_7subsets[.$n];.}

batch_trend_10subsets<-data.table(expand.grid(
    n=names(random_10subsets),
    dir=c(1),
    w=91,
    stringsAsFactors = FALSE
)) %>% {.$u<-random_10subsets[.$n];.}


batch_result<-do.call(rbind,do.call(mapply,c(backtest,batch,SIMPLIFY=FALSE)))
batch_trend_window_result<-do.call(rbind,do.call(mapply,c(backtest,batch_trend_window,SIMPLIFY=FALSE)))

batch_all_91trend_result<-backtest("U",colnames(ccy_tr),dir=1,w=91,tret=ccy_tr)

batch_trend_3subsets_result<-c(
  list(FUN=backtest_subset),
  batch_trend_3subsets,
  list(MoreArgs=list(tret=ccy_tr,source_backtest=batch_all_91trend_result)),
  list(SIMPLIFY=FALSE)
) %>%
{do.call(mapply,.)} %>%
{do.call(rbind,.)}
  
batch_trend_7subsets_result<-c(
  list(FUN=backtest_subset),
  batch_trend_7subsets,
  list(MoreArgs=list(tret=ccy_tr,source_backtest=batch_all_91trend_result)),
  list(SIMPLIFY=FALSE)
) %>%
{do.call(mapply,.)} %>%
{do.call(rbind,.)}
  
batch_trend_10subsets_result<-c(
  list(FUN=backtest_subset_ls),
  batch_trend_10subsets,
  list(MoreArgs=list(tret=ccy_tr,source_backtest=batch_all_91trend_result,s=3)),
  list(SIMPLIFY=FALSE)
) %>%
{do.call(mapply,.)} %>%
{do.call(rbind,.)}

gg_trend<-results2plot(batch_result[type=="trend" & window==91 & name %in% c("g10","g3","g10xg3")]) %>% 
  ggplot() +
  geom_line(aes(x=date,y=perf*100,col=group,group=group)) +
  ggtitle(paste0("91-day Trend"))

gg_rev<-results2plot(batch_result[type=="reversion" & window==91]) %>% 
  ggplot() +
  geom_line(aes(x=date,y=perf*100,col=group,group=group))+
  ggtitle(paste0("45-day Reversion"))




@

We would like to understand how parameter selection drives strategy performance. Because we do not have
access to the actual implementation, we construct a very simple trend model which we beliece captures 
the essential characteristics of a trend strategy. The model uses a single signal: the sign of total 
returns over a rolling window. If the sign is positive, we go long. If negative we go short. Otherwise
we take no position. This is the simplest signal one can construct. In addition, doing the reverse 
corresponds to a mean reversion strategy. No thresholds or significance tests are used. This is a benchmark,
not a strategy. 

Strategy parameters are:

\begin{itemize}
\item Currency universe
\item Window length
\end{itemize}


\vskip 5mm

\begin{center}
\Sexpr{make_plot(
  plot(gg_trend),
  width="15cm",
  height="15cm",
  envir=environment()
)}
\end{center}

\vskip 5mm

\begin{center}
\Sexpr{ntable(
  df=results2df(batch_result)[strat=="trend"],
  scale="0.75",
  title="backtest result summary"
)}
\end{center}

\newpage
\section{Sensitivity to parameters}
<<,cache=FALSE, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results="hide">>=

gg_window <- results2df(batch_trend_window_result) %>%
  melt(id.vars=c("name","window"),measure.vars="sharpe",variable.name="stat",value.name="sharpe") %>%
  ggplot() +
  geom_line(aes(x=window,y=sharpe,col=name),size=2)+
  ggtitle(paste0("Sharpe vs window length"))

gg_3subset <- results2df(batch_trend_3subsets_result) %>%
  ggplot(aes(x=sharpe)) +
  geom_histogram(bins=50)+
  ggtitle(paste0("Sharpe vs 3-currency subset selection"))+
  geom_vline(xintercept = results2df(batch_result)[strat=="trend" & name=="g3",sharpe],color=rgb(1,0,0),alpha=0.5,size=2)

gg_7subset <- results2df(batch_trend_7subsets_result) %>%
  ggplot(aes(x=sharpe)) +
  geom_histogram(bins=50)+
  ggtitle(paste0("Sharpe vs 7-currency subset selection"))+
  geom_vline(xintercept = results2df(batch_result)[strat=="trend" & name=="g10xg3",sharpe],color=rgb(1,0,0),alpha=0.5,size=2)

strat_long<-batch_result[type=="trend" & name=="g3",strat][[1]]
strat_short<-batch_result[type=="trend" & name=="g10xg3",strat][[1]]

gg_10subset <- results2df(batch_trend_10subsets_result) %>%
  ggplot(aes(x=sharpe)) +
  geom_histogram(bins=50)+
  ggtitle(paste0("Sharpe vs 3vs7-currency subset selection"))+
  geom_vline(xintercept = sharpe(strat_long-strat_short),color=rgb(1,0,0),alpha=0.5,size=2)


@
\vskip 5mm

\begin{center}
\begin{tabular}{m{10cm} m{10cm}}
\multicolumn{1}{c}{Random vs actual 3-ccy choice} &
\multicolumn{1}{c}{Random vs actual 7-ccy choice} \\
\Sexpr{make_plot(
  plot(gg_3subset),
  width="10cm",
  height="10cm",
  envir=environment()
)}
&
\Sexpr{make_plot(
  plot(gg_7subset),
  width="10cm",
  height="10cm",
  envir=environment()
)}
\\
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{m{10cm} m{10cm}}
\multicolumn{1}{c}{Random vs actual 3vs7-ccy choice} &
\multicolumn{1}{c}{Window size} \\
\Sexpr{make_plot(
  plot(gg_10subset),
  width="10cm",
  height="10cm",
  envir=environment()
)}
&
\Sexpr{make_plot(
  plot(gg_window),
  width="10cm",
  height="10cm",
  envir=environment()
)}
\\
\end{tabular}
\end{center}


\newpage
\section{This document }

\vskip 5mm

\begin{center}
\begin{tabular}{l l}
\hline
timestamp & \Sexpr{latexTranslate(as.character(Sys.timeDate()))} \\
git id & \Sexpr{system("git rev-parse HEAD",TRUE)} \\
user & \Sexpr{latexTranslate(gsub("\\\\","/",system("whoami",TRUE)))} \\
\hline
\end{tabular}
\end{center}

\vskip 5mm

\end{document}
